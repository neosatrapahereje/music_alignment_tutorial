{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f474445",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neosatrapahereje/music_alignment_tutorial/blob/main/Symbolic_Music_Alignment.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b411e",
   "metadata": {},
   "source": [
    "# Symbolic Music Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install partitura\n",
    "    ! pip install partitura\n",
    "    ! pip install fastdtw\n",
    "\n",
    "    # To be able to access helper modules in the repo for this tutorial\n",
    "    # (not necessary if the jupyter notebook is run locally instead of google colab)\n",
    "    !git clone https://github.com/cpjku/vienna4x22.git\n",
    "    !git clone https://github.com/neosatrapahereje/music_alignment_tutorial\n",
    "    import sys\n",
    "    sys.path.insert(0, \"./music_alignment_tutorial/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing some stuff\n",
    "import os \n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import partitura as pt\n",
    "\n",
    "from alignment import fast_dynamic_time_warping, greedy_note_alignment\n",
    "\n",
    "from typing import List\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "if IN_COLAB:\n",
    "    V4X22_DATASET_DIR = \"./vienna4x22\"\n",
    "else:\n",
    "    # Path to the Vienna 4x22 dataset\n",
    "    from load_data import init_dataset\n",
    "\n",
    "    V4X22_DATASET_DIR = init_dataset()\n",
    "\n",
    "MUSICXML_DIR = os.path.join(V4X22_DATASET_DIR, \"musicxml\")\n",
    "MIDI_DIR = os.path.join(V4X22_DATASET_DIR, \"midi\")\n",
    "MATCH_DIR = os.path.join(V4X22_DATASET_DIR, \"match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b323c",
   "metadata": {},
   "source": [
    "## Feature Representations\n",
    "\n",
    "To make musical data comparable for alignment algorithms, the first step is to extract features that capture relevant aspects while suppressing irrelevant details.\n",
    "\n",
    "In this lecture we are going to focus on 2 common features representations:\n",
    "\n",
    "1. Piano Rolls\n",
    "2. Pitch Class Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc0f43",
   "metadata": {},
   "source": [
    "### Piano Rolls\n",
    "\n",
    "A piano roll is a 2D representation of (MIDI) pitch and time. We can extract piano rolls from symbolic music files with Partitura!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load a score and a performance of the score\n",
    "\n",
    "# Path to the MusicXML file\n",
    "score_fn = os.path.join(MUSICXML_DIR, \"Chopin_op10_no3.musicxml\")\n",
    "performance_fn = os.path.join(MIDI_DIR, \"Chopin_op10_no3_p01.mid\")\n",
    "\n",
    "score = pt.load_score(score_fn)\n",
    "performance = pt.load_performance(performance_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-wagon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute piano roll\n",
    "use_piano_range = False\n",
    "score_pr = pt.utils.music.compute_pianoroll(\n",
    "    note_info=score,\n",
    "    piano_range=use_piano_range,\n",
    ")\n",
    "\n",
    "performance_pr = pt.utils.music.compute_pianoroll(\n",
    "    note_info=performance,\n",
    "    piano_range=use_piano_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(2, figsize=(10, 7))\n",
    "axes[0].imshow(\n",
    "    score_pr.todense(),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "axes[1].imshow(\n",
    "    performance_pr.todense(),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "y_label = \"Piano key\" if use_piano_range else \"MIDI pitch\"\n",
    "axes[0].set_ylabel(y_label)\n",
    "axes[1].set_ylabel(y_label)\n",
    "axes[0].set_title(\"Score\")\n",
    "axes[1].set_title(\"Performance\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-addition",
   "metadata": {},
   "source": [
    "For more information, see the documentation of  [`compute_pianoroll`](https://partitura.readthedocs.io/en/latest/modules/partitura.utils.html#partitura.utils.compute_pianoroll)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-oxford",
   "metadata": {},
   "source": [
    "### Pitch Class Distributions\n",
    "\n",
    "These features are the symbolic equivalent to *chroma* features in audio. This representation is basically a piano roll that has been folded into a single octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pc_pr = pt.utils.music.compute_pitch_class_pianoroll(\n",
    "    score,\n",
    "    normalize=True,\n",
    "    time_unit=\"beat\",\n",
    "    time_div=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-mediterranean",
   "metadata": {},
   "source": [
    "Let's plot this feature and compare it to a piano roll of the same score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pr = pt.utils.music.compute_pianoroll(\n",
    "    note_info=score,\n",
    "    time_unit=\"beat\",\n",
    "    time_div=4,\n",
    "    piano_range=False,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, figsize=(10, 5), sharex=True)\n",
    "\n",
    "axes[0].imshow(\n",
    "    score_pc_pr,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "axes[0].set_title(\"Pitch Class Distribution\")\n",
    "axes[0].set_ylabel(\"Pitch classes\")\n",
    "axes[1].imshow(\n",
    "    score_pr.todense(),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "axes[1].set_title(\"Piano roll\")\n",
    "axes[1].set_ylabel(\"MIDI pitch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8d3c",
   "metadata": {},
   "source": [
    "## Alignment Methods\n",
    "\n",
    "We move now to methods for computing the alignment between features from one version of a piece of music to another. Common methods are dynamic programming approaches like dynamic time warping (DTW) and probabilistic approaches like hidden Markov models.\n",
    "\n",
    "### Alignments with Dynamic Time Warping.\n",
    "\n",
    "* DTW is a dynamic programming algorithm to find the **optimal** alignment between to time-dependent sequences. \n",
    "* Unlike Euclidean distance, which requires point-to-point correspondence between two sequences, DTW allows for elastic transformations of the time axis, enabling it to find an optimal match between two sequences that may vary in time or speed.\n",
    "* The DTW algorithm finds the alignment between two sequence in three steps:\n",
    "\n",
    "    1. Compute the pairwise distance between elements in sequence $\\mathbf{X}$ and $\\mathbf{Y}$.\n",
    "    2. Compute the accumulated cost matrix $\\mathbf{D}$. The element $D_{ij}$ represents the \"cost\" or \"effort\" required for $x_i$ and $y_j$ to be aligned.\n",
    "    3. Find the best alignment by backtracking \n",
    "\n",
    "We will explore these steps with a simple example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d9861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from slideshow_helper import dtw_example\n",
    "\n",
    "dtw_example(interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2ac9e",
   "metadata": {},
   "source": [
    "## Music Alignment with DTW\n",
    "\n",
    "1. Compute features from score and the performance\n",
    "2. Compute the alignment between the sequences of features using DTW\n",
    "3. Use a greedy note alignment to estimate the note-wise alignment\n",
    "\n",
    "Let's compare alignment using piano rolls and pitch class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the ground truth alignment\n",
    "gt_alignment_fn = os.path.join(MATCH_DIR, \"Chopin_op10_no3_p01.match\")\n",
    "\n",
    "# Load the alignment and the performance\n",
    "performance, gt_alignment = pt.load_match(\n",
    "    gt_alignment_fn, pedal_threshold=127, first_note_at_zero=True\n",
    ")\n",
    "pnote_array = performance.note_array()\n",
    "\n",
    "# Load the score\n",
    "score_fn = os.path.join(MUSICXML_DIR, \"Chopin_op10_no3.musicxml\")\n",
    "score = pt.load_score(score_fn)\n",
    "snote_array = score.note_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed0dc9",
   "metadata": {},
   "source": [
    "Compute alignment using pitch class distributions as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the features\n",
    "score_pcr, sidx = pt.utils.music.compute_pitch_class_pianoroll(\n",
    "    note_info=score,\n",
    "    time_unit=\"beat\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "performance_pcr, pidx = pt.utils.music.compute_pitch_class_pianoroll(\n",
    "    note_info=performance,\n",
    "    time_unit=\"sec\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "reference_features = score_pcr.T\n",
    "performance_features = performance_pcr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW\n",
    "dtw_pcr_warping_path = fast_dynamic_time_warping(\n",
    "    X=reference_features,\n",
    "    Y=performance_features,\n",
    "    metric=\"cityblock\",\n",
    ")\n",
    "\n",
    "dtw_pcr_alignment = greedy_note_alignment(\n",
    "    warping_path=dtw_pcr_warping_path,\n",
    "    idx1=sidx,\n",
    "    note_array1=snote_array,\n",
    "    idx2=pidx,\n",
    "    note_array2=pnote_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1051c",
   "metadata": {},
   "source": [
    "And now we compute the alignments using piano rolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the features\n",
    "score_pr, sidx = pt.utils.music.compute_pianoroll(\n",
    "    note_info=score,\n",
    "    time_unit=\"beat\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    piano_range=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "performance_pr, pidx = pt.utils.music.compute_pianoroll(\n",
    "    note_info=performance,\n",
    "    time_unit=\"sec\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    piano_range=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "reference_features = score_pr.toarray().T\n",
    "performance_features = performance_pr.toarray().T\n",
    "\n",
    "# DTW\n",
    "dtw_pr_warping_path = fast_dynamic_time_warping(\n",
    "    X=reference_features,\n",
    "    Y=performance_features,\n",
    "    metric=\"cityblock\",\n",
    ")\n",
    "\n",
    "dtw_pr_alignment = greedy_note_alignment(\n",
    "    warping_path=dtw_pr_warping_path,\n",
    "    idx1=sidx,\n",
    "    note_array1=snote_array,\n",
    "    idx2=pidx,\n",
    "    note_array2=pnote_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].plot(\n",
    "    dtw_pr_warping_path[:, 0],\n",
    "    dtw_pr_warping_path[:, 1],\n",
    "    label=\"DTW (piano roll)\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    dtw_pcr_warping_path[:, 0],\n",
    "    dtw_pcr_warping_path[:, 1],\n",
    "    label=\"DTW (pitch class)\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    dtw_pr_warping_path[:, 0],\n",
    "    dtw_pr_warping_path[:, 1],\n",
    "    label=\"DTW (piano roll)\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    dtw_pcr_warping_path[:, 0],\n",
    "    dtw_pcr_warping_path[:, 1],\n",
    "    label=\"DTW (pitch class)\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Index in score\")\n",
    "axes[1].set_xlabel(\"Index in score\")\n",
    "axes[0].set_ylabel(\"Index in performance\")\n",
    "axes[1].set_xlim((200, 300))\n",
    "axes[1].set_ylim((450, 550))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927655f",
   "metadata": {},
   "source": [
    "We can compare the performance of the alignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-integral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper import evaluate_alignment_notewise\n",
    "\n",
    "print(f\"Method\\tF-score\\tPrecision\\tRecall\")\n",
    "\n",
    "methods = [\n",
    "    (dtw_pr_alignment, \"DTW (piano roll)\"),\n",
    "    (dtw_pcr_alignment, \"DTW (pitch class)\"),\n",
    "]\n",
    "\n",
    "for align, method in methods:\n",
    "    precision, recall, fscore = evaluate_alignment_notewise(\n",
    "        prediction=align,\n",
    "        ground_truth=gt_alignment,\n",
    "    )\n",
    "    print(f\"{method}\\t{fscore:.4f}\\t{precision:.4f}\\t{recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-doctor",
   "metadata": {},
   "source": [
    "## Alignment Applications: Comparing Expressive Performances\n",
    "\n",
    "In this example, we are going to compare tempo curves of different performances of the same piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import compute_tempo_curve\n",
    "\n",
    "# get all match files\n",
    "piece = \"Chopin_op10_no3\"\n",
    "matchfiles = glob.glob(os.path.join(MATCH_DIR, f\"{piece}_p*.match\"))\n",
    "matchfiles.sort()\n",
    "\n",
    "# Load the score\n",
    "score_fn = os.path.join(MUSICXML_DIR, f\"{piece}.musicxml\")\n",
    "score = pt.load_score(score_fn)\n",
    "snote_array = score.note_array()\n",
    "\n",
    "tempo_curves = []\n",
    "for i, matchfile in enumerate(matchfiles):\n",
    "    # load alignment\n",
    "    perf, alignment = pt.load_match(matchfile)\n",
    "    # Compute tempo curves\n",
    "    tempo_curve = compute_tempo_curve(\n",
    "        perf=perf,\n",
    "        score=snote_array,\n",
    "        alignment=alignment,\n",
    "    )\n",
    "    tempo_curves.append(tempo_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-honey",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15, 8))\n",
    "color = plt.cm.rainbow(np.linspace(0, 1, len(tempo_curves)))\n",
    "for i, tempo_info in enumerate(tempo_curves):\n",
    "    score_time = tempo_info[:, 0]\n",
    "    tempo_curve = tempo_info[:, 1]\n",
    "    ax.plot(\n",
    "        score_time,\n",
    "        tempo_curve,\n",
    "        label=f\"pianist {i + 1:02d}\",\n",
    "        alpha=0.4,\n",
    "        c=color[i],\n",
    "    )\n",
    "\n",
    "# plot average performance\n",
    "ax.plot(\n",
    "    score_time,\n",
    "    np.mean([tc[:, 1] for tc in tempo_curves], axis=0),\n",
    "    label=\"average\",\n",
    "    c=\"black\",\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# get starting time of each measure in the score\n",
    "measure_times = score[0].beat_map(\n",
    "    [measure.start.t for measure in score[0].iter_all(pt.score.Measure)]\n",
    ")\n",
    "# do not include pickup measure\n",
    "measure_times = measure_times[measure_times >= 0]\n",
    "ax.set_title(piece)\n",
    "ax.set_xlabel(\"Score time (beats)\")\n",
    "ax.set_ylabel(\"Tempo (bpm)\")\n",
    "ax.set_xticks(measure_times)\n",
    "plt.legend(frameon=False, bbox_to_anchor=(1.15, 0.9))\n",
    "plt.grid(axis=\"x\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
