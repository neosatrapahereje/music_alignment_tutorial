{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f474445",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neosatrapahereje/music_alignment_tutorial/blob/main/Symbolic_Music_Alignment.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install python packages\n",
    "    ! pip install partitura\n",
    "    ! pip install fastdtw\n",
    "\n",
    "    # To be able to access helper modules in the repo for this tutorial\n",
    "    # (not necessary if the jupyter notebook is run locally instead of google colab)\n",
    "    !git clone https://github.com/cpjku/vienna4x22.git\n",
    "    !git clone https://github.com/neosatrapahereje/music_alignment_tutorial\n",
    "    import sys\n",
    "    sys.path.insert(0, \"./music_alignment_tutorial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b411e",
   "metadata": {},
   "source": [
    "# Symbolic Music Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c072482",
   "metadata": {},
   "source": [
    "Automatic Music Alignment refers to the task of linking or matching two musical signals of the same musical work. This can be, e.g., matching *different performances* of the same piece, or matching the performance of a piece with its musical score.\n",
    "\n",
    "<img src=\"figures/alignment_figure.gif\" alt=\"alignment_figure\" width=\"600\"/>\n",
    "\n",
    "The following figure shows a common music alignment pipeline:\n",
    "\n",
    "<img src=\"figures/alignment_pipeline.png\" alt=\"alignment_pipeline\" width=\"600\"/>\n",
    "\n",
    "In this notebook we are going to explore these components in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing some stuff\n",
    "import os \n",
    "# import glob\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import partitura as pt\n",
    "\n",
    "from alignment import fast_dynamic_time_warping, greedy_note_alignment\n",
    "\n",
    "from typing import List\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "if IN_COLAB:\n",
    "    V4X22_DATASET_DIR = \"./vienna4x22\"\n",
    "else:\n",
    "    # Path to the Vienna 4x22 dataset\n",
    "    from load_data import init_dataset\n",
    "\n",
    "    V4X22_DATASET_DIR = init_dataset()\n",
    "\n",
    "MUSICXML_DIR = os.path.join(V4X22_DATASET_DIR, \"musicxml\")\n",
    "MIDI_DIR = os.path.join(V4X22_DATASET_DIR, \"midi\")\n",
    "MATCH_DIR = os.path.join(V4X22_DATASET_DIR, \"match\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1679d",
   "metadata": {},
   "source": [
    "## 1. Music Representation\n",
    "\n",
    "In this tutorial we will focus on symbolic music representations, such that can be stored in formats such as MIDI, MusicXML or MEI, and that can be generated by editors like MuseScore, Finale, etc.\n",
    "\n",
    "### 1.1 Audio vs. Symbolic Alignment\n",
    "\n",
    "* In **Audio-based alignment**, the alignment itself typically refers to  of *timestamps* (in absolute time in seconds) in one audio recording of a musical work to the corresponding *timestamp* in another recording. (In audio recordings, identifying individual notes is not a trivial task)\n",
    "\n",
    "\n",
    "* In **Symbolic-based alignment**, we can have two types of alignment:\n",
    "    * **Time-wise alignments**: similar to audio-based alignment, we can map timestamps (in symbolic time units like musical beats or MIDI ticks) from one version of the work to another (e.g., a MIDI performance to a score in MusicXML/MEI/Humdrum format). \n",
    "    * **Note-wise alignment**: We can map individual symbolic music elements (most commonly notes) from one version to another. This is very useful for modeling expressive performance.\n",
    "\n",
    "### 1.2 Time\n",
    "\n",
    "* **Offline**: Alignment of two *recordings/documents* (i.e., audio recordings, MIDI performances, MusicXML scores, etc.). These recordings/documents can be in any of the modalities described above, the important thing being that the music is occurring in real-time.\n",
    "\n",
    "* **Online**: Alignment of a live (i.e., real time) performance to the music encoded in a target document (e.g., a pre-annotated audio recording, a symbolic score, etc.). The problem of real time online alignment is known in the MIR literature a **score following**, and can be useful in live interactive settings, such as automatic accompaniment systems\n",
    "\n",
    "In this tutorial we are going to focus on the case of offline alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b323c",
   "metadata": {},
   "source": [
    "## 2. Feature Representations\n",
    "\n",
    "To make musical data comparable for alignment algorithms, the first step is to extract features that capture relevant aspects while suppressing irrelevant details.\n",
    "\n",
    "In this lecture we are going to focus on piano rolls, one of the most commonly used features in symbolic music processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc0f43",
   "metadata": {},
   "source": [
    "### Piano Rolls\n",
    "\n",
    "A piano roll is a 2D representation of (MIDI) pitch and time. We can extract piano rolls from symbolic music files with Partitura!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load a score and a performance of the score\n",
    "\n",
    "# Path to the MusicXML file\n",
    "score_fn = os.path.join(MUSICXML_DIR, \"Chopin_op10_no3.musicxml\")\n",
    "performance_fn = os.path.join(MIDI_DIR, \"Chopin_op10_no3_p01.mid\")\n",
    "\n",
    "score = pt.load_score(score_fn)\n",
    "performance = pt.load_performance(performance_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-wagon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute piano roll\n",
    "use_piano_range = False\n",
    "score_pr = pt.utils.music.compute_pianoroll(\n",
    "    note_info=score,\n",
    "    piano_range=use_piano_range,\n",
    ")\n",
    "\n",
    "performance_pr = pt.utils.music.compute_pianoroll(\n",
    "    note_info=performance,\n",
    "    piano_range=use_piano_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(2, figsize=(10, 7))\n",
    "axes[0].imshow(\n",
    "    score_pr.todense(),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "axes[1].imshow(\n",
    "    performance_pr.todense(),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"gray\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "y_label = \"Piano key\" if use_piano_range else \"MIDI pitch\"\n",
    "axes[0].set_ylabel(y_label)\n",
    "axes[1].set_ylabel(y_label)\n",
    "axes[0].set_title(\"Score\")\n",
    "axes[1].set_title(\"Performance\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-addition",
   "metadata": {},
   "source": [
    "For more information, see the documentation of  [`compute_pianoroll`](https://partitura.readthedocs.io/en/latest/modules/partitura.utils.html#partitura.utils.compute_pianoroll)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8d3c",
   "metadata": {},
   "source": [
    "## 3. Alignment Methods\n",
    "\n",
    "We move now to methods for computing the alignment between features from one version of a piece of music to another. Common methods are dynamic programming approaches like dynamic time warping (DTW) and probabilistic approaches like hidden Markov models.\n",
    "\n",
    "### 3.1 Dynamic Time Warping.\n",
    "\n",
    "* DTW is a [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) algorithm to find the **optimal** alignment between to time-dependent sequences. \n",
    "* Unlike Euclidean distance, which requires point-to-point correspondence between two sequences, DTW allows for elastic transformations of the time axis, enabling it to find an optimal match between two sequences that may vary in time.\n",
    "* The DTW algorithm finds the alignment between two sequence in three steps:\n",
    "\n",
    "    1. Compute the pairwise distance between elements in sequence $\\mathbf{X}$ (e.g., the performance) and $\\mathbf{Y}$ (e.g., the score).\n",
    "    2. Compute the *accumulated cost matrix* $\\mathbf{D}$. The element $\\mathbf{D}[i,j]$ represents the \"cost\" required for $x_i$ and $y_j$ to be aligned. For estimating this matrix, we use a recursive equation (this is the dynamic programming part!)\n",
    "    3. Find the best alignment by backtracking, starting from the end of the performance.\n",
    "\n",
    "Here is a more detailed tutorial on DTW: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neosatrapahereje/music_alignment_tutorial/blob/main/DTW_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2ac9e",
   "metadata": {},
   "source": [
    "## 4. Music Alignment with DTW\n",
    "\n",
    "1. Compute features from score and the performance (in this case the piano rolls)\n",
    "2. Compute the alignment between the sequences of features using DTW. This produces a time-wise alignment that tells us which time in the performance (in seconds) corresponds to which time in the score (in musical beats).\n",
    "3. To get a note-level alignment, we match notes in the performance to notes in the score considering the time-wise alignment, and matching notes greedily by pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the ground truth alignment\n",
    "gt_alignment_fn = os.path.join(MATCH_DIR, \"Chopin_op10_no3_p01.match\")\n",
    "\n",
    "# Load the alignment and the performance\n",
    "performance, gt_alignment = pt.load_match(\n",
    "    gt_alignment_fn, pedal_threshold=127, first_note_at_zero=True\n",
    ")\n",
    "pnote_array = performance.note_array()\n",
    "\n",
    "# Load the score\n",
    "score_fn = os.path.join(MUSICXML_DIR, \"Chopin_op10_no3.musicxml\")\n",
    "score = pt.load_score(score_fn)\n",
    "snote_array = score.note_array()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1051c",
   "metadata": {},
   "source": [
    "And now we compute the alignments using piano rolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the features\n",
    "score_pr, sidx = pt.utils.music.compute_pianoroll(\n",
    "    note_info=score,\n",
    "    time_unit=\"beat\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    piano_range=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "performance_pr, pidx = pt.utils.music.compute_pianoroll(\n",
    "    note_info=performance,\n",
    "    time_unit=\"sec\",\n",
    "    time_div=8,\n",
    "    return_idxs=True,\n",
    "    piano_range=True,\n",
    "    binary=True,\n",
    "    note_separation=True,\n",
    ")\n",
    "\n",
    "reference_features = score_pr.toarray().T\n",
    "performance_features = performance_pr.toarray().T\n",
    "\n",
    "# DTW\n",
    "dtw_pr_warping_path = fast_dynamic_time_warping(\n",
    "    X=reference_features,\n",
    "    Y=performance_features,\n",
    "    metric=\"cityblock\",\n",
    ")\n",
    "\n",
    "# Greedy note-level alignment\n",
    "dtw_pr_alignment = greedy_note_alignment(\n",
    "    warping_path=dtw_pr_warping_path,\n",
    "    idx1=sidx,\n",
    "    note_array1=snote_array,\n",
    "    idx2=pidx,\n",
    "    note_array2=pnote_array,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927655f",
   "metadata": {},
   "source": [
    "We can compare the performance of the alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-integral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper import evaluate_alignment_notewise\n",
    "\n",
    "print(f\"Method\\tF-score\\tPrecision\\tRecall\")\n",
    "\n",
    "methods = [\n",
    "    (dtw_pr_alignment, \"DTW (piano roll)\"),\n",
    "]\n",
    "\n",
    "for align, method in methods:\n",
    "    precision, recall, fscore = evaluate_alignment_notewise(\n",
    "        prediction=align,\n",
    "        ground_truth=gt_alignment,\n",
    "    )\n",
    "    print(f\"{method}\\t{fscore:.4f}\\t{precision:.4f}\\t{recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-doctor",
   "metadata": {},
   "source": [
    "## 5. Alignment Applications: Comparing Expressive Performances\n",
    "\n",
    "In this example, we are going to compare tempo curves of different performances of the same piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import plot_tempo_curves\n",
    "\n",
    "# get all match files\n",
    "piece = \"Mozart_K331_1st-mov\"\n",
    "# piece = \"Schubert_D783_no15\"\n",
    "# piece = \"Chopin_op38\"\n",
    "# piece = \"Chopin_op10_no3\"\n",
    "\n",
    "plot_tempo_curves(piece, V4X22_DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6dafd",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "* In this notebook we learned about automatic music alignment for symbolic music\n",
    "* We explored different parts of a pipeline of a system for alignment (features, alignment algorithms)\n",
    "* We learned about the dynamic time warping algorithm, and how it can be used to align a performance to its score.\n",
    "* Finally, we showed an application of alignment, focusing on comparing of expressive tempo curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2257b3",
   "metadata": {},
   "source": [
    "## 7. References for Further Reading\n",
    "\n",
    "* Müller, M. (2021). [Music Synchronization](https://doi.org/10.1007/978-3-030-69808-9_3). In: Fundamentals of Music Processing. Springer, Cham. \n",
    "* Peter, S.D., Cancino-Chacón, C.E., Foscarin, F., McLeod, A.P., Henkel, F., Karystinaios, E. and Widmer, G., (2023). [Automatic Note-Level Score-to-Performance Alignments in the ASAP Dataset](https://transactions.ismir.net/articles/10.5334/tismir.149). Transactions of the International Society for Music Information Retrieval, 6(1), p.27–42.\n",
    "* Foscarin, F., Karystinaios, E., Peter, S. D., Cancino-Chacón, C., Grachten, M., and Widmer, G.  (2022) [The match file format: Encoding Alignments between Scores and Performances](https://arxiv.org/pdf/2206.01104.pdf). In Proceedings of the Music Encoding Conference. Halifax, Canada\n",
    "* Cancino-Chacón, C., Peter, S. D.,  Karystinaios, E., Foscarin, F., Grachten, M., and Widmer, G.  (2022) [Partitura: A Python Package for Symbolic Music Processing](https://arxiv.org/pdf/2206.01071.pdf). In Proceedings of the Music Encoding Conference. Halifax, Canada \n",
    "* Peter, S. D. (2023) [Online Symbolic Music Alignment With Offline Reinforcement Learning](https://archives.ismir.net/ismir2023/paper/000075.pdf). Proceedings of the 24th International Society for Music Information Retrieval Conference, 634–641. Milan, Italy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
